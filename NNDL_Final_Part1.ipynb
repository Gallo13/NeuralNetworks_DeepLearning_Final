{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jessica Gallo\n",
    "# CSC767 Neural Networks and Deep Learning\n",
    "# Final\n",
    "# Part 1\n",
    "# Execute forward and backward modes of neural network for 3 iterations\n",
    "# (epochs). This network comprises of a hidden layer with 3 ReLU units and a\n",
    "# squared-error loss. (Note: Use tanh as activation function in the output unit\n",
    "# and ReLU for hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[[ 0.75  0.8 ]\n",
      " [ 0.2   0.05]\n",
      " [-0.75  0.8 ]\n",
      " [ 0.2  -0.05]]\n",
      "Output:\n",
      "[[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]]\n",
      "Predicted Output: \n",
      "[[0.09827181]\n",
      " [0.01121453]\n",
      " [0.06327535]\n",
      " [0.00594493]]\n",
      "Loss: \n",
      "0.9833225284863827\n",
      "\n",
      "\n",
      "Input: \n",
      "[[ 0.75  0.8 ]\n",
      " [ 0.2   0.05]\n",
      " [-0.75  0.8 ]\n",
      " [ 0.2  -0.05]]\n",
      "Output:\n",
      "[[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]]\n",
      "Predicted Output: \n",
      "[[0.7467511 ]\n",
      " [0.19426234]\n",
      " [0.01071758]\n",
      " [0.15869158]]\n",
      "Loss: \n",
      "0.7693660925235322\n",
      "\n",
      "\n",
      "Input: \n",
      "[[ 0.75  0.8 ]\n",
      " [ 0.2   0.05]\n",
      " [-0.75  0.8 ]\n",
      " [ 0.2  -0.05]]\n",
      "Output:\n",
      "[[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]]\n",
      "Predicted Output: \n",
      "[[ 0.60236805]\n",
      " [ 0.29632006]\n",
      " [-0.33662496]\n",
      " [ 0.34921737]]\n",
      "Loss: \n",
      "0.7284326415051565\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "x = np.array(([0.75, 0.80], [0.20, 0.05], [-0.75, 0.80], [0.20, -0.05]))\n",
    "y = np.array(([1], [1], [-1], [-1]))\n",
    "\n",
    "inputSize = 2\n",
    "outputSize = 1\n",
    "hiddenSize = 3\n",
    "\n",
    "# weights\n",
    "w1 = np.array([[0.60, 0.70, 0.00], [0.01, 0.43, 0.88]])\n",
    "w2 = np.array([[0.02], [0.03], [0.09]])\n",
    "\n",
    "\n",
    "def sigmoid(s):\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "\n",
    "def relu(s):\n",
    "    return np.maximum(0, s)\n",
    "\n",
    "\n",
    "def dRelu(z):\n",
    "    return np.where(z <= 0)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    t = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    return t\n",
    "\n",
    "\n",
    "def dTanh(x):\n",
    "    t = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    dt = 1 - t * t\n",
    "    return dt\n",
    "\n",
    "\n",
    "# Forward\n",
    "def forwardProp(x):\n",
    "    z = np.dot(x, w1)  # dot product\n",
    "    z2 = relu(z)  # relu activation\n",
    "    z3 = np.dot(z2, w2)  # dot product\n",
    "    o = tanh(z3)  # tanh activation function\n",
    "    return o\n",
    "\n",
    "\n",
    "def backwardProp(x, y, o, w1, w2, z2):\n",
    "    o_error = y - o  # error in output\n",
    "    o_delta = o_error * dTanh(o)  # derivative of tanh to error\n",
    "\n",
    "    z2_error = o_delta.dot(w2.T)  # z2 error: hidden layer weight made error\n",
    "    z2_delta = z2_error * dTanh(z2)  # derivative of tanh to z2 error\n",
    "\n",
    "    w1 += x.T.dot(z2_delta)  # adjusting first set (input to hidden) weights\n",
    "    w2 += z2.T.dot(o_delta)\n",
    "\n",
    "\n",
    "z = np.dot(x, w1)\n",
    "z2 = relu(z)\n",
    "\n",
    "\n",
    "def train(x, y):\n",
    "    o = forwardProp(x)\n",
    "    backwardProp(x, y, o, w1, w2, z2)\n",
    "\n",
    "# 1st epoch\n",
    "print('Input: \\n' + str(x))\n",
    "print('Output:\\n' + str(y))\n",
    "print('Predicted Output: \\n' + str(forwardProp(x)))\n",
    "print('Loss: \\n' + str(np.mean(np.square(y-forwardProp(x)))))  # mean sum squared loss\n",
    "print('\\n')\n",
    "\n",
    "# 2nd epoch\n",
    "train(x, y)\n",
    "print('Input: \\n' + str(x))\n",
    "print('Output:\\n' + str(y))\n",
    "print('Predicted Output: \\n' + str(forwardProp(x)))\n",
    "print('Loss: \\n' + str(np.mean(np.square(y-forwardProp(x)))))  # mean sum squared loss\n",
    "print('\\n')\n",
    "\n",
    "# 3rd epoch\n",
    "train(x, y)\n",
    "print('Input: \\n' + str(x))\n",
    "print('Output:\\n' + str(y))\n",
    "print('Predicted Output: \\n' + str(forwardProp(x)))\n",
    "print('Loss: \\n' + str(np.mean(np.square(y-forwardProp(x)))))  # mean sum squared loss\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
